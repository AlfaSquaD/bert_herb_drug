{"cells":[{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18192,"status":"ok","timestamp":1658875041263,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"},"user_tz":-120},"id":"qdX19l16bJIJ","outputId":"daeb717f-f816-4082-ea5d-b144a574133b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in c:\\users\\ensar\\anaconda3\\lib\\site-packages (4.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from transformers) (0.7.0)\n","Requirement already satisfied: filelock in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n","Requirement already satisfied: tqdm>=4.27 in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from transformers) (4.62.3)\n","Requirement already satisfied: sacremoses in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from transformers) (0.0.53)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from transformers) (2.26.0)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from transformers) (1.23.1)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from transformers) (21.0)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n","Requirement already satisfied: colorama in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.7)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from requests->transformers) (3.2)\n","Requirement already satisfied: joblib in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (8.0.3)\n","Requirement already satisfied: six in c:\\users\\ensar\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":7833,"status":"ok","timestamp":1658875051716,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"},"user_tz":-120},"id":"onnSPijma5fY"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import random\n","import json\n","import time\n","import datetime\n","import os\n","\n","from torch.utils.data import TensorDataset, random_split\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","import torch\n","from transformers import BertTokenizer\n","from transformers import get_linear_schedule_with_warmup"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1658875070647,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"},"user_tz":-120},"id":"j4S08QD7bfcA","outputId":"b637ddba-4501-4422-a367-c2133dce9124"},"outputs":[{"name":"stderr","output_type":"stream","text":["'pwd' is not recognized as an internal or external command,\n","operable program or batch file.\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":232,"status":"ok","timestamp":1658875091501,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"},"user_tz":-120},"id":"6WDjtzKAqLXz"},"outputs":[],"source":["model_out = \"./output_biobert\""]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":658,"status":"ok","timestamp":1658875134705,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"},"user_tz":-120},"id":"eOWaw3oobj54","outputId":"4ae87745-92a4-44c0-a338-bb94d1f59019"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>sentences</th>\n","      <th>entity_1_mention</th>\n","      <th>entity_2_mention</th>\n","      <th>type</th>\n","      <th>kfold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>it is unclear whether some component of the &lt;e...</td>\n","      <td>ginseng</td>\n","      <td>digoxin</td>\n","      <td>SPECULATIVE</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>in vitro studies from our laboratory suggest t...</td>\n","      <td>kaempferol</td>\n","      <td>erythromycin</td>\n","      <td>POSITIVE</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>&lt;e1&gt; digoxin &lt;/e1&gt; therapy was maintained at a...</td>\n","      <td>digoxin</td>\n","      <td>ginseng</td>\n","      <td>POSITIVE</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>.32) for &lt;e1&gt; ginkgo &lt;/e1&gt; treatment, and 1.00...</td>\n","      <td>ginkgo</td>\n","      <td>cyp2c9</td>\n","      <td>NEGATIVE</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>other herbal remedies with the potential to mo...</td>\n","      <td>ginseng</td>\n","      <td>cytochrome p450</td>\n","      <td>POSITIVE</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                                          sentences  \\\n","0           0  it is unclear whether some component of the <e...   \n","1           1  in vitro studies from our laboratory suggest t...   \n","2           2  <e1> digoxin </e1> therapy was maintained at a...   \n","3           3  .32) for <e1> ginkgo </e1> treatment, and 1.00...   \n","4           4  other herbal remedies with the potential to mo...   \n","\n","  entity_1_mention entity_2_mention         type  kfold  \n","0          ginseng          digoxin  SPECULATIVE      0  \n","1       kaempferol     erythromycin     POSITIVE      0  \n","2          digoxin          ginseng     POSITIVE      0  \n","3           ginkgo           cyp2c9     NEGATIVE      0  \n","4          ginseng  cytochrome p450     POSITIVE      0  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["data_fname = 'datasets/train_new.csv'\n","df = pd.read_csv(data_fname)\n","df.head()"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":223,"status":"ok","timestamp":1658875142622,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"},"user_tz":-120},"id":"v7cc7XGMb4tM","outputId":"f250387a-597f-4b07-a9d6-d8fc11e92189"},"outputs":[{"data":{"text/plain":["POSITIVE       223\n","SPECULATIVE     89\n","NEGATIVE        26\n","Name: type, dtype: int64"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df['type'].value_counts()"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":251,"status":"ok","timestamp":1658875151667,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"},"user_tz":-120},"id":"E5ap4RwMb7FM","outputId":"f56e5057-586c-420f-a63f-84ca99f171ca"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>sentences</th>\n","      <th>entity_1_mention</th>\n","      <th>entity_2_mention</th>\n","      <th>type</th>\n","      <th>kfold</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>it is unclear whether some component of the &lt;e...</td>\n","      <td>ginseng</td>\n","      <td>digoxin</td>\n","      <td>SPECULATIVE</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>in vitro studies from our laboratory suggest t...</td>\n","      <td>kaempferol</td>\n","      <td>erythromycin</td>\n","      <td>POSITIVE</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>&lt;e1&gt; digoxin &lt;/e1&gt; therapy was maintained at a...</td>\n","      <td>digoxin</td>\n","      <td>ginseng</td>\n","      <td>POSITIVE</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>.32) for &lt;e1&gt; ginkgo &lt;/e1&gt; treatment, and 1.00...</td>\n","      <td>ginkgo</td>\n","      <td>cyp2c9</td>\n","      <td>NEGATIVE</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>other herbal remedies with the potential to mo...</td>\n","      <td>ginseng</td>\n","      <td>cytochrome p450</td>\n","      <td>POSITIVE</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                                          sentences  \\\n","0           0  it is unclear whether some component of the <e...   \n","1           1  in vitro studies from our laboratory suggest t...   \n","2           2  <e1> digoxin </e1> therapy was maintained at a...   \n","3           3  .32) for <e1> ginkgo </e1> treatment, and 1.00...   \n","4           4  other herbal remedies with the potential to mo...   \n","\n","  entity_1_mention entity_2_mention         type  kfold  label  \n","0          ginseng          digoxin  SPECULATIVE      0      1  \n","1       kaempferol     erythromycin     POSITIVE      0      0  \n","2          digoxin          ginseng     POSITIVE      0      0  \n","3           ginkgo           cyp2c9     NEGATIVE      0      2  \n","4          ginseng  cytochrome p450     POSITIVE      0      0  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["label_map_dic = {\n","    \"POSITIVE\": 0,\n","    \"SPECULATIVE\": 1,\n","    \"NEGATIVE\": 2,\n","}\n","df['label'] = df['type'].map(label_map_dic)\n","df.head()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["ed60765855874d7889f36f1ad2bea204","fa29fe7e690d43ac9760bada97ef72b3","0251aafed1ce457eb338fac7819f5192","4f0a94fa40f84f41b6bbadd952a959b3","d82237bc6f204a04a51faf1c27a62233","a9773f080dbc49ffa2e201f19728c7de","f275abbf72aa49288fabde1baba5f05b","86962bd3c1954e9880801f736572794b","341848a4150d40529f6a263a83519575","071fd387768348959c8f8dd54b1a1753","100e5fd13879449f90ee5e65518004ab","63b8e927b1f040f896c564ffc96bc26d","ee5fa8cfd694491bb9fced7873ac799c","50c8b54b0f3b47249b6812f828c0e11b","c09cd7b90076425e9f4240f371d9b9d0","ba30753f6ab247a9bd0ba768aabf091f","881eccb806ca4ac9bf905c7023f7d54a","f730f82346904716aef888fa0a647985","acdd41101e1c469a8d833eb1ccfaf9b1","b8b6241760b648eaa7c99079e53f2056","593805cae75c494d8aff42620dbae71b","a2ecd9c2c3e240f3b564577109c02399","d016d8c27773411197ea50dc9f2ee842","5f6c6ac78c1e4615a79143b04df79647","6e8ef0c5e7d74da4be0f87a0f39adbe9","8225d4e5656942a6a54af60671a87e95","be155c2418ed4cd4a76bcbfdc5f7a524","ad4df579156545e3a1aee68cec83af19","a59a7178f6d74b18a239a9b2acb5c039","18edba8c76a74100a4ce538f2b6b324a","d7793bc09a4a43878f43c5d619bd97da","fec8015457474049be4de65e3b3b5bae","e13b41e019a144f99ca41dda0c9231cc"]},"executionInfo":{"elapsed":2656,"status":"ok","timestamp":1658875159937,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"},"user_tz":-120},"id":"YmDfcmkWcHqo","outputId":"a7e9127d-c528-4f8d-ff44-ee8b5ac87e99"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: 100%|██████████| 208k/208k [00:00<00:00, 511kB/s] \n","Downloading: 100%|██████████| 313/313 [00:00<00:00, 156kB/s]\n"]}],"source":["# Instantiate the Bert tokenizer\n","# sic-ber  biobert \n","tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.1', do_lower_case=True)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":234,"status":"ok","timestamp":1658875165221,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"},"user_tz":-120},"id":"fqgK40YWcMhX"},"outputs":[],"source":["def get_inputs(df):\n","    input_ids = []\n","    attention_masks = []\n","    labels = []\n","\n","    MAX_LENGTH = 128\n","\n","    # For every sentence...\n","    for i,row in df.iterrows():\n","        #print(row['entity1'])\n","        sent = row['sentences'] + str('[SEP]') + row['entity_1_mention'] + str('[SEP]') + row['entity_2_mention'] \n","        labels.append(int(row['label']))\n","        encoded_dict = tokenizer.encode_plus(\n","                          sent,                          # Sentence to encode.\n","                          add_special_tokens = True,     # Add '[CLS]' and '[SEP]'\n","                          max_length = MAX_LENGTH,       # Pad & truncate all sentences.\n","                          pad_to_max_length = True,\n","                          return_attention_mask = True,  # Construct attn. masks.\n","                          return_tensors = 'pt',         # Return pytorch tensors.\n","                      )\n","\n","        # Add the encoded sentence to the list.    \n","        input_ids.append(encoded_dict['input_ids'])\n","\n","        # And its attention mask (simply differentiates padding from non-padding).\n","        attention_masks.append(encoded_dict['attention_mask'])\n","\n","    # Convert the lists into tensors.\n","    input_ids = torch.cat(input_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    labels = torch.tensor(labels)\n","    \n","    return input_ids,attention_masks,labels"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1722,"status":"ok","timestamp":1658875175251,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"},"user_tz":-120},"id":"XzAsZ3PDcP9N","outputId":"1a9a06ac-441e-4c39-b110-b83101d4408c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","c:\\Users\\ensar\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}],"source":["kfold = 0\n","train_df = df[df.kfold != kfold].reset_index(drop=True)\n","valid_df = df[df.kfold == kfold].reset_index(drop=True)  \n","\n","train_input_ids, train_attention_masks, train_labels = get_inputs(train_df)\n","valid_input_ids, valid_attention_masks, valid_labels = get_inputs(valid_df)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":241,"status":"ok","timestamp":1658875276856,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"},"user_tz":-120},"id":"6i4eOHlJcRT9"},"outputs":[],"source":["train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n","val_dataset = TensorDataset(valid_input_ids, valid_attention_masks, valid_labels)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1658875277783,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"},"user_tz":-120},"id":"Qjc9DbwLcU8G"},"outputs":[],"source":["\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["761835562cef445c9ae11fc83b9f643c","47273d9addd948eb8d9e976a95e47b96","ce9c5505e2dd41988dd6f0d6492d81c0","50f8f4c1eec94aa7a9c7256a26c956a3","1732459fd93944a7a10fe08f3b0609fe","c6c3dcf81c1443bcb3d17ee2570514ce","e7b05011da5c403dadda810efdf425d1","c8472810f617482fbf4ec4e567635226","c8d4b263a6384f54b8d3cac0911ffb98","556952b3e4c840e88f334cb06ab06711","efc94f2a4358462aa697bae46c2c37ba"]},"executionInfo":{"elapsed":19317,"status":"ok","timestamp":1658875304248,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"},"user_tz":-120},"id":"o9RfCsjVcW8I","outputId":"9785ebdc-2b9b-444c-941f-7dedc96ad912"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: 100%|██████████| 416M/416M [00:15<00:00, 27.5MB/s] \n","Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = BertForSequenceClassification.from_pretrained(\n","               'dmis-lab/biobert-base-cased-v1.1', \n","               num_labels = len(label_map_dic), # The number of output labels. 2 for binary classification.  \n","               output_attentions = False,\n","               output_hidden_states = False)   \n","\n","# Tell pytorch to run this model on the GPU.\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# send model to device\n","model.to(device);"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":234,"status":"ok","timestamp":1658875310999,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"},"user_tz":-120},"id":"DIEkyN6qcY9a","outputId":"120195a4-4d66-43bb-e7c2-2aef7dff4eab"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\ensar\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["optimizer = AdamW(model.parameters(),\n","                  lr = 5e-5, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 2,I have already seen that the model starts overfitting beyound 2 epochs\n","epochs = 5\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                       num_warmup_steps = 0, # Default value in run_glue.py\n","                       num_training_steps = total_steps)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1658875313706,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"},"user_tz":-120},"id":"_5pAMeN3cfqV"},"outputs":[],"source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","\n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43252,"status":"ok","timestamp":1658875359553,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"},"user_tz":-120},"id":"X9IGHIFRchHN","outputId":"d0e54d09-f6d8-413a-a773-2da61ac50bdf"},"outputs":[{"name":"stdout","output_type":"stream","text":["======== Epoch 1 / 5 ========\n","Training...\n","\n","  Average training loss: 0.8740\n","  Training epcoh took: 0:00:12\n","Saving model to ./output_biobert/models/bert_model_epoch1\n","\n","Running Validation...\n","  Accuracy: 0.8542\n","  Validation Loss: 0.5698\n","  Validation took: 0:00:01\n","======== Epoch 2 / 5 ========\n","Training...\n","\n","  Average training loss: 0.5713\n","  Training epcoh took: 0:00:09\n","Saving model to ./output_biobert/models/bert_model_epoch2\n","\n","Running Validation...\n","  Accuracy: 0.9167\n","  Validation Loss: 0.3897\n","  Validation took: 0:00:01\n","======== Epoch 3 / 5 ========\n","Training...\n","\n","  Average training loss: 0.3577\n","  Training epcoh took: 0:00:09\n","Saving model to ./output_biobert/models/bert_model_epoch3\n","\n","Running Validation...\n","  Accuracy: 0.9479\n","  Validation Loss: 0.2520\n","  Validation took: 0:00:01\n","======== Epoch 4 / 5 ========\n","Training...\n","\n","  Average training loss: 0.2230\n","  Training epcoh took: 0:00:09\n","Saving model to ./output_biobert/models/bert_model_epoch4\n","\n","Running Validation...\n","  Accuracy: 0.9583\n","  Validation Loss: 0.1864\n","  Validation took: 0:00:01\n","======== Epoch 5 / 5 ========\n","Training...\n","\n","  Average training loss: 0.1532\n","  Training epcoh took: 0:00:09\n","Saving model to ./output_biobert/models/bert_model_epoch5\n","\n","Running Validation...\n","  Accuracy: 0.9583\n","  Validation Loss: 0.1758\n","  Validation took: 0:00:01\n","\n","Training complete!\n","Total training took 0:01:01 (h:mm:ss)\n"]}],"source":["# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# store a number of quantities such as training and validation loss,validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","\n","    # training\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode.\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader andcopy each tensor to the GPU\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing abackward pass.\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        outputs = model(b_input_ids, \n","                token_type_ids=None, \n","                attention_mask=b_input_mask, \n","                labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches\n","        loss= outputs[0]\n","        logits = outputs[1]  \n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","    \n","    # ========================================\n","    # Save model of every epoch\n","    output_dir = model_out + '/models/'\n","    # Create output directory if needed\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","    \n","    models_dir = output_dir + 'bert_model_epoch' + str(epoch_i + 1)\n","    # Create output directory if needed\n","    if not os.path.exists(models_dir):\n","        os.makedirs(models_dir)\n","\n","    print(\"Saving model to %s\" % models_dir)\n","\n","    # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","    # They can then be reloaded using `from_pretrained()`\n","    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","    model_to_save.save_pretrained(models_dir)\n","    tokenizer.save_pretrained(models_dir)\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0.0\n","    total_eval_loss = 0.0\n","    nb_eval_steps = 0.0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        with torch.no_grad():        \n","            outputs= model(b_input_ids, \n","                    token_type_ids=None, \n","                    attention_mask=b_input_mask,\n","                    labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        loss= outputs[0]\n","        logits = outputs[1] \n","        \n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.4f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.4f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":293,"status":"ok","timestamp":1658875373565,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"},"user_tz":-120},"id":"V-RR8R5cck-P","outputId":"8162bed4-b1be-4072-d51b-6a5a9d3dfc12"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.8740</td>\n","      <td>0.5698</td>\n","      <td>0.8542</td>\n","      <td>0:00:12</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.5713</td>\n","      <td>0.3897</td>\n","      <td>0.9167</td>\n","      <td>0:00:09</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.3577</td>\n","      <td>0.2520</td>\n","      <td>0.9479</td>\n","      <td>0:00:09</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.2230</td>\n","      <td>0.1864</td>\n","      <td>0.9583</td>\n","      <td>0:00:09</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.1532</td>\n","      <td>0.1758</td>\n","      <td>0.9583</td>\n","      <td>0:00:09</td>\n","      <td>0:00:01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1             0.8740       0.5698         0.8542       0:00:12         0:00:01\n","2             0.5713       0.3897         0.9167       0:00:09         0:00:01\n","3             0.3577       0.2520         0.9479       0:00:09         0:00:01\n","4             0.2230       0.1864         0.9583       0:00:09         0:00:01\n","5             0.1532       0.1758         0.9583       0:00:09         0:00:01"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","# Display floats with two decimal places.\n","pd.set_option('precision', 4)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","output_dir = model_out + '/models/'\n","# # Create output directory if needed\n","# if not os.path.exists(output_dir):\n","#     os.makedirs(output_dir)\n","\n","df_stats.to_csv(output_dir + 'df_train_stats.csv',index=None)\n","\n","# according df_stats, pick the best performace model\n","df_stats"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uTg7MUPid_d5"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOrpigorpzSbkwVnUhIF95E","name":"bert_train.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"972b6de16a1878fa6fcdbb27b0b6b0b2aa35566bf75b52396f9f47d7f37db45e"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"0251aafed1ce457eb338fac7819f5192":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_86962bd3c1954e9880801f736572794b","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_341848a4150d40529f6a263a83519575","value":231508}},"071fd387768348959c8f8dd54b1a1753":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"100e5fd13879449f90ee5e65518004ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1732459fd93944a7a10fe08f3b0609fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18edba8c76a74100a4ce538f2b6b324a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"341848a4150d40529f6a263a83519575":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"47273d9addd948eb8d9e976a95e47b96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6c3dcf81c1443bcb3d17ee2570514ce","placeholder":"​","style":"IPY_MODEL_e7b05011da5c403dadda810efdf425d1","value":"Downloading: 100%"}},"4f0a94fa40f84f41b6bbadd952a959b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_071fd387768348959c8f8dd54b1a1753","placeholder":"​","style":"IPY_MODEL_100e5fd13879449f90ee5e65518004ab","value":" 226k/226k [00:00&lt;00:00, 825kB/s]"}},"50c8b54b0f3b47249b6812f828c0e11b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_acdd41101e1c469a8d833eb1ccfaf9b1","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8b6241760b648eaa7c99079e53f2056","value":28}},"50f8f4c1eec94aa7a9c7256a26c956a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_556952b3e4c840e88f334cb06ab06711","placeholder":"​","style":"IPY_MODEL_efc94f2a4358462aa697bae46c2c37ba","value":" 420M/420M [00:10&lt;00:00, 42.7MB/s]"}},"556952b3e4c840e88f334cb06ab06711":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"593805cae75c494d8aff42620dbae71b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f6c6ac78c1e4615a79143b04df79647":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad4df579156545e3a1aee68cec83af19","placeholder":"​","style":"IPY_MODEL_a59a7178f6d74b18a239a9b2acb5c039","value":"Downloading: 100%"}},"63b8e927b1f040f896c564ffc96bc26d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee5fa8cfd694491bb9fced7873ac799c","IPY_MODEL_50c8b54b0f3b47249b6812f828c0e11b","IPY_MODEL_c09cd7b90076425e9f4240f371d9b9d0"],"layout":"IPY_MODEL_ba30753f6ab247a9bd0ba768aabf091f"}},"6e8ef0c5e7d74da4be0f87a0f39adbe9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18edba8c76a74100a4ce538f2b6b324a","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d7793bc09a4a43878f43c5d619bd97da","value":570}},"761835562cef445c9ae11fc83b9f643c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47273d9addd948eb8d9e976a95e47b96","IPY_MODEL_ce9c5505e2dd41988dd6f0d6492d81c0","IPY_MODEL_50f8f4c1eec94aa7a9c7256a26c956a3"],"layout":"IPY_MODEL_1732459fd93944a7a10fe08f3b0609fe"}},"8225d4e5656942a6a54af60671a87e95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fec8015457474049be4de65e3b3b5bae","placeholder":"​","style":"IPY_MODEL_e13b41e019a144f99ca41dda0c9231cc","value":" 570/570 [00:00&lt;00:00, 15.9kB/s]"}},"86962bd3c1954e9880801f736572794b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"881eccb806ca4ac9bf905c7023f7d54a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2ecd9c2c3e240f3b564577109c02399":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a59a7178f6d74b18a239a9b2acb5c039":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a9773f080dbc49ffa2e201f19728c7de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acdd41101e1c469a8d833eb1ccfaf9b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad4df579156545e3a1aee68cec83af19":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8b6241760b648eaa7c99079e53f2056":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba30753f6ab247a9bd0ba768aabf091f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be155c2418ed4cd4a76bcbfdc5f7a524":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c09cd7b90076425e9f4240f371d9b9d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_593805cae75c494d8aff42620dbae71b","placeholder":"​","style":"IPY_MODEL_a2ecd9c2c3e240f3b564577109c02399","value":" 28.0/28.0 [00:00&lt;00:00, 830B/s]"}},"c6c3dcf81c1443bcb3d17ee2570514ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8472810f617482fbf4ec4e567635226":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8d4b263a6384f54b8d3cac0911ffb98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ce9c5505e2dd41988dd6f0d6492d81c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8472810f617482fbf4ec4e567635226","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c8d4b263a6384f54b8d3cac0911ffb98","value":440473133}},"d016d8c27773411197ea50dc9f2ee842":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5f6c6ac78c1e4615a79143b04df79647","IPY_MODEL_6e8ef0c5e7d74da4be0f87a0f39adbe9","IPY_MODEL_8225d4e5656942a6a54af60671a87e95"],"layout":"IPY_MODEL_be155c2418ed4cd4a76bcbfdc5f7a524"}},"d7793bc09a4a43878f43c5d619bd97da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d82237bc6f204a04a51faf1c27a62233":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e13b41e019a144f99ca41dda0c9231cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7b05011da5c403dadda810efdf425d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed60765855874d7889f36f1ad2bea204":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa29fe7e690d43ac9760bada97ef72b3","IPY_MODEL_0251aafed1ce457eb338fac7819f5192","IPY_MODEL_4f0a94fa40f84f41b6bbadd952a959b3"],"layout":"IPY_MODEL_d82237bc6f204a04a51faf1c27a62233"}},"ee5fa8cfd694491bb9fced7873ac799c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_881eccb806ca4ac9bf905c7023f7d54a","placeholder":"​","style":"IPY_MODEL_f730f82346904716aef888fa0a647985","value":"Downloading: 100%"}},"efc94f2a4358462aa697bae46c2c37ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f275abbf72aa49288fabde1baba5f05b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f730f82346904716aef888fa0a647985":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa29fe7e690d43ac9760bada97ef72b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9773f080dbc49ffa2e201f19728c7de","placeholder":"​","style":"IPY_MODEL_f275abbf72aa49288fabde1baba5f05b","value":"Downloading: 100%"}},"fec8015457474049be4de65e3b3b5bae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
