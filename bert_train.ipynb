{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_train.ipynb","provenance":[],"authorship_tag":"ABX9TyOrpigorpzSbkwVnUhIF95E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"ed60765855874d7889f36f1ad2bea204":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa29fe7e690d43ac9760bada97ef72b3","IPY_MODEL_0251aafed1ce457eb338fac7819f5192","IPY_MODEL_4f0a94fa40f84f41b6bbadd952a959b3"],"layout":"IPY_MODEL_d82237bc6f204a04a51faf1c27a62233"}},"fa29fe7e690d43ac9760bada97ef72b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9773f080dbc49ffa2e201f19728c7de","placeholder":"​","style":"IPY_MODEL_f275abbf72aa49288fabde1baba5f05b","value":"Downloading: 100%"}},"0251aafed1ce457eb338fac7819f5192":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_86962bd3c1954e9880801f736572794b","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_341848a4150d40529f6a263a83519575","value":231508}},"4f0a94fa40f84f41b6bbadd952a959b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_071fd387768348959c8f8dd54b1a1753","placeholder":"​","style":"IPY_MODEL_100e5fd13879449f90ee5e65518004ab","value":" 226k/226k [00:00&lt;00:00, 825kB/s]"}},"d82237bc6f204a04a51faf1c27a62233":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9773f080dbc49ffa2e201f19728c7de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f275abbf72aa49288fabde1baba5f05b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86962bd3c1954e9880801f736572794b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"341848a4150d40529f6a263a83519575":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"071fd387768348959c8f8dd54b1a1753":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"100e5fd13879449f90ee5e65518004ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63b8e927b1f040f896c564ffc96bc26d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee5fa8cfd694491bb9fced7873ac799c","IPY_MODEL_50c8b54b0f3b47249b6812f828c0e11b","IPY_MODEL_c09cd7b90076425e9f4240f371d9b9d0"],"layout":"IPY_MODEL_ba30753f6ab247a9bd0ba768aabf091f"}},"ee5fa8cfd694491bb9fced7873ac799c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_881eccb806ca4ac9bf905c7023f7d54a","placeholder":"​","style":"IPY_MODEL_f730f82346904716aef888fa0a647985","value":"Downloading: 100%"}},"50c8b54b0f3b47249b6812f828c0e11b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_acdd41101e1c469a8d833eb1ccfaf9b1","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8b6241760b648eaa7c99079e53f2056","value":28}},"c09cd7b90076425e9f4240f371d9b9d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_593805cae75c494d8aff42620dbae71b","placeholder":"​","style":"IPY_MODEL_a2ecd9c2c3e240f3b564577109c02399","value":" 28.0/28.0 [00:00&lt;00:00, 830B/s]"}},"ba30753f6ab247a9bd0ba768aabf091f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"881eccb806ca4ac9bf905c7023f7d54a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f730f82346904716aef888fa0a647985":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"acdd41101e1c469a8d833eb1ccfaf9b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8b6241760b648eaa7c99079e53f2056":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"593805cae75c494d8aff42620dbae71b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2ecd9c2c3e240f3b564577109c02399":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d016d8c27773411197ea50dc9f2ee842":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5f6c6ac78c1e4615a79143b04df79647","IPY_MODEL_6e8ef0c5e7d74da4be0f87a0f39adbe9","IPY_MODEL_8225d4e5656942a6a54af60671a87e95"],"layout":"IPY_MODEL_be155c2418ed4cd4a76bcbfdc5f7a524"}},"5f6c6ac78c1e4615a79143b04df79647":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad4df579156545e3a1aee68cec83af19","placeholder":"​","style":"IPY_MODEL_a59a7178f6d74b18a239a9b2acb5c039","value":"Downloading: 100%"}},"6e8ef0c5e7d74da4be0f87a0f39adbe9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18edba8c76a74100a4ce538f2b6b324a","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d7793bc09a4a43878f43c5d619bd97da","value":570}},"8225d4e5656942a6a54af60671a87e95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fec8015457474049be4de65e3b3b5bae","placeholder":"​","style":"IPY_MODEL_e13b41e019a144f99ca41dda0c9231cc","value":" 570/570 [00:00&lt;00:00, 15.9kB/s]"}},"be155c2418ed4cd4a76bcbfdc5f7a524":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad4df579156545e3a1aee68cec83af19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a59a7178f6d74b18a239a9b2acb5c039":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18edba8c76a74100a4ce538f2b6b324a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7793bc09a4a43878f43c5d619bd97da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fec8015457474049be4de65e3b3b5bae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e13b41e019a144f99ca41dda0c9231cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"761835562cef445c9ae11fc83b9f643c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47273d9addd948eb8d9e976a95e47b96","IPY_MODEL_ce9c5505e2dd41988dd6f0d6492d81c0","IPY_MODEL_50f8f4c1eec94aa7a9c7256a26c956a3"],"layout":"IPY_MODEL_1732459fd93944a7a10fe08f3b0609fe"}},"47273d9addd948eb8d9e976a95e47b96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6c3dcf81c1443bcb3d17ee2570514ce","placeholder":"​","style":"IPY_MODEL_e7b05011da5c403dadda810efdf425d1","value":"Downloading: 100%"}},"ce9c5505e2dd41988dd6f0d6492d81c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8472810f617482fbf4ec4e567635226","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c8d4b263a6384f54b8d3cac0911ffb98","value":440473133}},"50f8f4c1eec94aa7a9c7256a26c956a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_556952b3e4c840e88f334cb06ab06711","placeholder":"​","style":"IPY_MODEL_efc94f2a4358462aa697bae46c2c37ba","value":" 420M/420M [00:10&lt;00:00, 42.7MB/s]"}},"1732459fd93944a7a10fe08f3b0609fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6c3dcf81c1443bcb3d17ee2570514ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7b05011da5c403dadda810efdf425d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8472810f617482fbf4ec4e567635226":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8d4b263a6384f54b8d3cac0911ffb98":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"556952b3e4c840e88f334cb06ab06711":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efc94f2a4358462aa697bae46c2c37ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qdX19l16bJIJ","executionInfo":{"status":"ok","timestamp":1658875041263,"user_tz":-120,"elapsed":18192,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}},"outputId":"daeb717f-f816-4082-ea5d-b144a574133b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 7.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 56.2 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 7.7 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 12.9 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"onnSPijma5fY","executionInfo":{"status":"ok","timestamp":1658875051716,"user_tz":-120,"elapsed":7833,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import random\n","import json\n","import time\n","import datetime\n","import os\n","\n","from torch.utils.data import TensorDataset, random_split\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","import torch\n","from transformers import BertTokenizer\n","from transformers import get_linear_schedule_with_warmup"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"06JK6PqubD5l","executionInfo":{"status":"ok","timestamp":1658875070645,"user_tz":-120,"elapsed":15493,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}},"outputId":"c2418267-351a-4d0c-852c-604d82b9fd99"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /drive\n"]}]},{"cell_type":"code","source":["os.chdir(\"/drive/MyDrive/bert_herb_drug/\")"],"metadata":{"id":"mX9NVFAjbW1l","executionInfo":{"status":"ok","timestamp":1658875070646,"user_tz":-120,"elapsed":10,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j4S08QD7bfcA","executionInfo":{"status":"ok","timestamp":1658875070647,"user_tz":-120,"elapsed":10,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}},"outputId":"b637ddba-4501-4422-a367-c2133dce9124"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/drive/MyDrive/bert_herb_drug\n"]}]},{"cell_type":"code","source":["model_out = \"./output_new\""],"metadata":{"id":"6WDjtzKAqLXz","executionInfo":{"status":"ok","timestamp":1658875091501,"user_tz":-120,"elapsed":232,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["data_fname = 'datasets/train_new.csv'\n","df = pd.read_csv(data_fname)\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"eOWaw3oobj54","executionInfo":{"status":"ok","timestamp":1658875134705,"user_tz":-120,"elapsed":658,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}},"outputId":"4ae87745-92a4-44c0-a338-bb94d1f59019"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0                                          sentences  \\\n","0           0  interactions of several commonly used herbal m...   \n","1           1  0 years, and their most-used medications were ...   \n","2           2   <e1> khat </e1>  chewing has been shown to re...   \n","3           3   conclusion: the growth inhibitory activity of...   \n","4           4  by taking advantage of the high protein bindin...   \n","\n","  entity_1_mention entity_2_mention         type  kfold  \n","0     milk thistle        indinavir     POSITIVE      0  \n","1             mint     atorvastatin  SPECULATIVE      0  \n","2             khat      amoxicillin     POSITIVE      0  \n","3     t. bellerica      doxorubicin     POSITIVE      0  \n","4          chan su          digoxin     POSITIVE      0  "],"text/html":["\n","  <div id=\"df-28d3dd58-42b3-4da7-96a5-356150562f2f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>sentences</th>\n","      <th>entity_1_mention</th>\n","      <th>entity_2_mention</th>\n","      <th>type</th>\n","      <th>kfold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>interactions of several commonly used herbal m...</td>\n","      <td>milk thistle</td>\n","      <td>indinavir</td>\n","      <td>POSITIVE</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0 years, and their most-used medications were ...</td>\n","      <td>mint</td>\n","      <td>atorvastatin</td>\n","      <td>SPECULATIVE</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>&lt;e1&gt; khat &lt;/e1&gt;  chewing has been shown to re...</td>\n","      <td>khat</td>\n","      <td>amoxicillin</td>\n","      <td>POSITIVE</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>conclusion: the growth inhibitory activity of...</td>\n","      <td>t. bellerica</td>\n","      <td>doxorubicin</td>\n","      <td>POSITIVE</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>by taking advantage of the high protein bindin...</td>\n","      <td>chan su</td>\n","      <td>digoxin</td>\n","      <td>POSITIVE</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28d3dd58-42b3-4da7-96a5-356150562f2f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-28d3dd58-42b3-4da7-96a5-356150562f2f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-28d3dd58-42b3-4da7-96a5-356150562f2f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["df['type'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v7cc7XGMb4tM","executionInfo":{"status":"ok","timestamp":1658875142622,"user_tz":-120,"elapsed":223,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}},"outputId":"f250387a-597f-4b07-a9d6-d8fc11e92189"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["POSITIVE       245\n","SPECULATIVE    102\n","NEGATIVE        27\n","Name: type, dtype: int64"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["label_map_dic = {\n","    \"POSITIVE\": 0,\n","    \"SPECULATIVE\": 1,\n","    \"NEGATIVE\": 2,\n","}\n","df['label'] = df['type'].map(label_map_dic)\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"E5ap4RwMb7FM","executionInfo":{"status":"ok","timestamp":1658875151667,"user_tz":-120,"elapsed":251,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}},"outputId":"f56e5057-586c-420f-a63f-84ca99f171ca"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0                                          sentences  \\\n","0           0  interactions of several commonly used herbal m...   \n","1           1  0 years, and their most-used medications were ...   \n","2           2   <e1> khat </e1>  chewing has been shown to re...   \n","3           3   conclusion: the growth inhibitory activity of...   \n","4           4  by taking advantage of the high protein bindin...   \n","\n","  entity_1_mention entity_2_mention         type  kfold  label  \n","0     milk thistle        indinavir     POSITIVE      0      0  \n","1             mint     atorvastatin  SPECULATIVE      0      1  \n","2             khat      amoxicillin     POSITIVE      0      0  \n","3     t. bellerica      doxorubicin     POSITIVE      0      0  \n","4          chan su          digoxin     POSITIVE      0      0  "],"text/html":["\n","  <div id=\"df-3c1efd1a-258a-4d1b-9ddf-45fbf9fc57a5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>sentences</th>\n","      <th>entity_1_mention</th>\n","      <th>entity_2_mention</th>\n","      <th>type</th>\n","      <th>kfold</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>interactions of several commonly used herbal m...</td>\n","      <td>milk thistle</td>\n","      <td>indinavir</td>\n","      <td>POSITIVE</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0 years, and their most-used medications were ...</td>\n","      <td>mint</td>\n","      <td>atorvastatin</td>\n","      <td>SPECULATIVE</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>&lt;e1&gt; khat &lt;/e1&gt;  chewing has been shown to re...</td>\n","      <td>khat</td>\n","      <td>amoxicillin</td>\n","      <td>POSITIVE</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>conclusion: the growth inhibitory activity of...</td>\n","      <td>t. bellerica</td>\n","      <td>doxorubicin</td>\n","      <td>POSITIVE</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>by taking advantage of the high protein bindin...</td>\n","      <td>chan su</td>\n","      <td>digoxin</td>\n","      <td>POSITIVE</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c1efd1a-258a-4d1b-9ddf-45fbf9fc57a5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3c1efd1a-258a-4d1b-9ddf-45fbf9fc57a5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3c1efd1a-258a-4d1b-9ddf-45fbf9fc57a5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Instantiate the Bert tokenizer\n","# sic-ber  biobert \n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"metadata":{"id":"YmDfcmkWcHqo","executionInfo":{"status":"ok","timestamp":1658875159937,"user_tz":-120,"elapsed":2656,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}},"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["ed60765855874d7889f36f1ad2bea204","fa29fe7e690d43ac9760bada97ef72b3","0251aafed1ce457eb338fac7819f5192","4f0a94fa40f84f41b6bbadd952a959b3","d82237bc6f204a04a51faf1c27a62233","a9773f080dbc49ffa2e201f19728c7de","f275abbf72aa49288fabde1baba5f05b","86962bd3c1954e9880801f736572794b","341848a4150d40529f6a263a83519575","071fd387768348959c8f8dd54b1a1753","100e5fd13879449f90ee5e65518004ab","63b8e927b1f040f896c564ffc96bc26d","ee5fa8cfd694491bb9fced7873ac799c","50c8b54b0f3b47249b6812f828c0e11b","c09cd7b90076425e9f4240f371d9b9d0","ba30753f6ab247a9bd0ba768aabf091f","881eccb806ca4ac9bf905c7023f7d54a","f730f82346904716aef888fa0a647985","acdd41101e1c469a8d833eb1ccfaf9b1","b8b6241760b648eaa7c99079e53f2056","593805cae75c494d8aff42620dbae71b","a2ecd9c2c3e240f3b564577109c02399","d016d8c27773411197ea50dc9f2ee842","5f6c6ac78c1e4615a79143b04df79647","6e8ef0c5e7d74da4be0f87a0f39adbe9","8225d4e5656942a6a54af60671a87e95","be155c2418ed4cd4a76bcbfdc5f7a524","ad4df579156545e3a1aee68cec83af19","a59a7178f6d74b18a239a9b2acb5c039","18edba8c76a74100a4ce538f2b6b324a","d7793bc09a4a43878f43c5d619bd97da","fec8015457474049be4de65e3b3b5bae","e13b41e019a144f99ca41dda0c9231cc"]},"outputId":"a7e9127d-c528-4f8d-ff44-ee8b5ac87e99"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed60765855874d7889f36f1ad2bea204"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63b8e927b1f040f896c564ffc96bc26d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d016d8c27773411197ea50dc9f2ee842"}},"metadata":{}}]},{"cell_type":"code","source":["def get_inputs(df):\n","    input_ids = []\n","    attention_masks = []\n","    labels = []\n","\n","    MAX_LENGTH = 128\n","\n","    # For every sentence...\n","    for i,row in df.iterrows():\n","        #print(row['entity1'])\n","        sent = row['sentences'] + str('[SEP]') + row['entity_1_mention'] + str('[SEP]') + row['entity_2_mention'] \n","        labels.append(int(row['label']))\n","        encoded_dict = tokenizer.encode_plus(\n","                          sent,                          # Sentence to encode.\n","                          add_special_tokens = True,     # Add '[CLS]' and '[SEP]'\n","                          max_length = MAX_LENGTH,       # Pad & truncate all sentences.\n","                          pad_to_max_length = True,\n","                          return_attention_mask = True,  # Construct attn. masks.\n","                          return_tensors = 'pt',         # Return pytorch tensors.\n","                      )\n","\n","        # Add the encoded sentence to the list.    \n","        input_ids.append(encoded_dict['input_ids'])\n","\n","        # And its attention mask (simply differentiates padding from non-padding).\n","        attention_masks.append(encoded_dict['attention_mask'])\n","\n","    # Convert the lists into tensors.\n","    input_ids = torch.cat(input_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    labels = torch.tensor(labels)\n","    \n","    return input_ids,attention_masks,labels"],"metadata":{"id":"fqgK40YWcMhX","executionInfo":{"status":"ok","timestamp":1658875165221,"user_tz":-120,"elapsed":234,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["kfold = 0\n","train_df = df[df.kfold != kfold].reset_index(drop=True)\n","valid_df = df[df.kfold == kfold].reset_index(drop=True)  \n","\n","train_input_ids, train_attention_masks, train_labels = get_inputs(train_df)\n","valid_input_ids, valid_attention_masks, valid_labels = get_inputs(valid_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XzAsZ3PDcP9N","executionInfo":{"status":"ok","timestamp":1658875175251,"user_tz":-120,"elapsed":1722,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}},"outputId":"1a9a06ac-441e-4c39-b110-b83101d4408c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n","val_dataset = TensorDataset(valid_input_ids, valid_attention_masks, valid_labels)"],"metadata":{"id":"6i4eOHlJcRT9","executionInfo":{"status":"ok","timestamp":1658875276856,"user_tz":-120,"elapsed":241,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )"],"metadata":{"id":"Qjc9DbwLcU8G","executionInfo":{"status":"ok","timestamp":1658875277783,"user_tz":-120,"elapsed":3,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["model = BertForSequenceClassification.from_pretrained(\n","               'bert-base-uncased', \n","               num_labels = len(label_map_dic), # The number of output labels. 2 for binary classification.  \n","               output_attentions = False,\n","               output_hidden_states = False)   \n","\n","# Tell pytorch to run this model on the GPU.\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# send model to device\n","model.to(device);"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["761835562cef445c9ae11fc83b9f643c","47273d9addd948eb8d9e976a95e47b96","ce9c5505e2dd41988dd6f0d6492d81c0","50f8f4c1eec94aa7a9c7256a26c956a3","1732459fd93944a7a10fe08f3b0609fe","c6c3dcf81c1443bcb3d17ee2570514ce","e7b05011da5c403dadda810efdf425d1","c8472810f617482fbf4ec4e567635226","c8d4b263a6384f54b8d3cac0911ffb98","556952b3e4c840e88f334cb06ab06711","efc94f2a4358462aa697bae46c2c37ba"]},"id":"o9RfCsjVcW8I","executionInfo":{"status":"ok","timestamp":1658875304248,"user_tz":-120,"elapsed":19317,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}},"outputId":"9785ebdc-2b9b-444c-941f-7dedc96ad912"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"761835562cef445c9ae11fc83b9f643c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["optimizer = AdamW(model.parameters(),\n","                  lr = 5e-5, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 2,I have already seen that the model starts overfitting beyound 2 epochs\n","epochs = 5\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                       num_warmup_steps = 0, # Default value in run_glue.py\n","                       num_training_steps = total_steps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DIEkyN6qcY9a","executionInfo":{"status":"ok","timestamp":1658875310999,"user_tz":-120,"elapsed":234,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}},"outputId":"120195a4-4d66-43bb-e7c2-2aef7dff4eab"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","\n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"_5pAMeN3cfqV","executionInfo":{"status":"ok","timestamp":1658875313706,"user_tz":-120,"elapsed":5,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# store a number of quantities such as training and validation loss,validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","\n","    # training\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode.\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader andcopy each tensor to the GPU\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing abackward pass.\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        outputs = model(b_input_ids, \n","                token_type_ids=None, \n","                attention_mask=b_input_mask, \n","                labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches\n","        loss= outputs[0]\n","        logits = outputs[1]  \n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","    \n","    # ========================================\n","    # Save model of every epoch\n","    output_dir = model_out + '/models/'\n","    # Create output directory if needed\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","    \n","    models_dir = output_dir + 'bert_model_epoch' + str(epoch_i + 1)\n","    # Create output directory if needed\n","    if not os.path.exists(models_dir):\n","        os.makedirs(models_dir)\n","\n","    print(\"Saving model to %s\" % models_dir)\n","\n","    # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","    # They can then be reloaded using `from_pretrained()`\n","    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","    model_to_save.save_pretrained(models_dir)\n","    tokenizer.save_pretrained(models_dir)\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0.0\n","    total_eval_loss = 0.0\n","    nb_eval_steps = 0.0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        with torch.no_grad():        \n","            outputs= model(b_input_ids, \n","                    token_type_ids=None, \n","                    attention_mask=b_input_mask,\n","                    labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        loss= outputs[0]\n","        logits = outputs[1] \n","        \n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.4f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.4f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X9IGHIFRchHN","executionInfo":{"status":"ok","timestamp":1658875359553,"user_tz":-120,"elapsed":43252,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}},"outputId":"d0e54d09-f6d8-413a-a773-2da61ac50bdf"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["======== Epoch 1 / 5 ========\n","Training...\n","\n","  Average training loss: 0.8643\n","  Training epcoh took: 0:00:08\n","Saving model to ./output_new/models/bert_model_epoch1\n","\n","Running Validation...\n","  Accuracy: 0.6932\n","  Validation Loss: 0.8141\n","  Validation took: 0:00:00\n","======== Epoch 2 / 5 ========\n","Training...\n","\n","  Average training loss: 0.6734\n","  Training epcoh took: 0:00:06\n","Saving model to ./output_new/models/bert_model_epoch2\n","\n","Running Validation...\n","  Accuracy: 0.8059\n","  Validation Loss: 0.6678\n","  Validation took: 0:00:01\n","======== Epoch 3 / 5 ========\n","Training...\n","\n","  Average training loss: 0.4784\n","  Training epcoh took: 0:00:06\n","Saving model to ./output_new/models/bert_model_epoch3\n","\n","Running Validation...\n","  Accuracy: 0.8059\n","  Validation Loss: 0.5443\n","  Validation took: 0:00:01\n","======== Epoch 4 / 5 ========\n","Training...\n","\n","  Average training loss: 0.3151\n","  Training epcoh took: 0:00:06\n","Saving model to ./output_new/models/bert_model_epoch4\n","\n","Running Validation...\n","  Accuracy: 0.7955\n","  Validation Loss: 0.4475\n","  Validation took: 0:00:01\n","======== Epoch 5 / 5 ========\n","Training...\n","\n","  Average training loss: 0.2284\n","  Training epcoh took: 0:00:06\n","Saving model to ./output_new/models/bert_model_epoch5\n","\n","Running Validation...\n","  Accuracy: 0.8258\n","  Validation Loss: 0.3700\n","  Validation took: 0:00:01\n","\n","Training complete!\n","Total training took 0:00:43 (h:mm:ss)\n"]}]},{"cell_type":"code","source":["import os\n","# Display floats with two decimal places.\n","pd.set_option('precision', 4)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","output_dir = model_out + '/models/'\n","# # Create output directory if needed\n","# if not os.path.exists(output_dir):\n","#     os.makedirs(output_dir)\n","\n","df_stats.to_csv(output_dir + 'df_train_stats.csv',index=None)\n","\n","# according df_stats, pick the best performace model\n","df_stats"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"V-RR8R5cck-P","executionInfo":{"status":"ok","timestamp":1658875373565,"user_tz":-120,"elapsed":293,"user":{"displayName":"Ensar Emir EROL","userId":"11672709509295299096"}},"outputId":"8162bed4-b1be-4072-d51b-6a5a9d3dfc12"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1             0.8643       0.8141         0.6932       0:00:08         0:00:00\n","2             0.6734       0.6678         0.8059       0:00:06         0:00:01\n","3             0.4784       0.5443         0.8059       0:00:06         0:00:01\n","4             0.3151       0.4475         0.7955       0:00:06         0:00:01\n","5             0.2284       0.3700         0.8258       0:00:06         0:00:01"],"text/html":["\n","  <div id=\"df-3b9c8a49-251c-42c8-9b34-f5cfd1fa98a6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.8643</td>\n","      <td>0.8141</td>\n","      <td>0.6932</td>\n","      <td>0:00:08</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.6734</td>\n","      <td>0.6678</td>\n","      <td>0.8059</td>\n","      <td>0:00:06</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.4784</td>\n","      <td>0.5443</td>\n","      <td>0.8059</td>\n","      <td>0:00:06</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.3151</td>\n","      <td>0.4475</td>\n","      <td>0.7955</td>\n","      <td>0:00:06</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.2284</td>\n","      <td>0.3700</td>\n","      <td>0.8258</td>\n","      <td>0:00:06</td>\n","      <td>0:00:01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b9c8a49-251c-42c8-9b34-f5cfd1fa98a6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3b9c8a49-251c-42c8-9b34-f5cfd1fa98a6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3b9c8a49-251c-42c8-9b34-f5cfd1fa98a6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":[""],"metadata":{"id":"uTg7MUPid_d5"},"execution_count":null,"outputs":[]}]}